############################################################################################
## Configuration file for GeneLab Illumina amplicon processing workflow                   ##
## Developed by Michael D. Lee (Mike.Lee@nasa.gov)                                        ##
############################################################################################

############################################################
##################### VARIABLES TO SET #####################
############################################################

###########################################################################
##### These need to match what is specific to our system and our data #####
###########################################################################

## Path to runsheet:
runsheet:
    "runsheet.csv"

## Set to PE for paired-end, SE for single-end. (if single-end, enter appropriate info below for the _R1_ variables and ignore the _R2_ ones)
data_type:
    "PE"

## single-column file with unique sample identifiers:
sample_info_file:
    "unique-sample-IDs.txt"

## input reads directory (can be relative to workflow directory, or needs to be full path):
raw_reads_dir:
    "../raw_reads/"

## raw read suffixes (region following the unique part of the sample names)
  # e.g. for paired-end data, Sample-1_R1_raw.fastq.gz would be _R1_raw.fastq.gz for 'raw_R1_suffix' below
  # e.g. if single-end, Sample-1.fastq.gz would be .fastq.gz for 'raw_R1_suffix' below, and 'raw_R2_suffix' won't be used
raw_R1_suffix:
    "_R1_raw.fastq.gz"
raw_R2_suffix:
    "_R2_raw.fastq.gz"

## if we are trimming primers or not (TRUE, or FALSE)
trim_primers:
    "TRUE"

## primer sequences if we are trimming them (include anchoring symbols, e.g. '^', as needed, see: https://cutadapt.readthedocs.io/en/stable/guide.html#adapter-types)
F_primer:
    "^AGAGTTTGATCCTGGCTCAG"
R_primer:
    "^TTACCGCGGCTGCTGGCAC"

## should cutadapt treat these as linked primers? (https://cutadapt.readthedocs.io/en/stable/recipes.html#trimming-amplicon-primers-from-paired-end-reads)
primers_linked:
    "TRUE"

## if primers are linked, we need to provide them as below, where the second half, following three periods, is the other primer reverse-complemented (see https://cutadapt.readthedocs.io/en/stable/recipes.html#trimming-amplicon-primers-from-paired-end-reads)
  # (can reverse complement while retaining ambiguous bases at this site: http://arep.med.harvard.edu/labgc/adnan/projects/Utilities/revcomp.html)
  # include anchoring symbols, e.g. '^', as needed, see: https://cutadapt.readthedocs.io/en/stable/guide.html#adapter-types
F_linked_primer:
    "^AGAGTTTGATCCTGGCTCAG...GTGCCAGCAGCCGCGGTAA"
R_linked_primer:
    "^TTACCGCGGCTGCTGGCAC...CTGAGCCAGGATCAAACTCT"

## discard untrimmed, sets the --discard-untrimmed option if TRUE
discard_untrimmed:
    "TRUE"

## target region (16S, 18S, or ITS is acceptable)
  # this determines which reference database is used for taxonomic classification
  # all are pulled from the pre-packaged DECIPHER downloads page here: http://www2.decipher.codes/Downloads.html
  # 16S uses SILVA
  # ITS uses UNITE
  # 18S uses PR2
target_region:
    "16S"

## concatenate only with dada2 instead of merging paired reads if TRUE
  # this is typically used with primers like 515-926, that captured 18S fragments that are typically too long to merge
  # note that 16S and 18S should have been separated already prior to running this workflow
  # this should likely be left as FALSE for any option other than "18S" above

concatenate_reads_only:
    "FALSE"

## values to be passed to dada2's filterAndTrim() function:
left_trunc:
    0
right_trunc:
    0
left_maxEE:
    1
right_maxEE:
    1

## minimum length threshold for cutadapt
min_cutadapt_len:
    1


######################################################################
##### The rest only need to be altered if we want to change them #####
######################################################################

## filename suffixes
primer_trimmed_R1_suffix:
    "_R1_trimmed.fastq.gz"
primer_trimmed_R2_suffix:
    "_R2_trimmed.fastq.gz"

filtered_R1_suffix:
    "_R1_filtered.fastq.gz"
filtered_R2_suffix:
    "_R2_filtered.fastq.gz"


## output prefix (if needed to distinguish from multiple primer sets, leave as empty string if not, include connecting symbol if adding, e.g. ITS-)
output_prefix:
    ""

## output directories (all relative to processing directory, they will be created if needed)
metadata_out_dir:
    "workflow_output/Metadata/"
fastqc_out_dir:
    "workflow_output/FastQC_Outputs/"
trimmed_reads_dir:
    "workflow_output/Trimmed_Sequence_Data/"
filtered_reads_dir:
    "workflow_output/Filtered_Sequence_Data/"
final_outputs_dir:
    "workflow_output/Final_Outputs/"
plots_dir:
    ""workflow_output/Final_Outputs/"Plots/"

############################################################
###################### GENERAL INFO ########################
############################################################
# Workflow is currently equipped to work with paired-end data only, and reads are expected to be gzipped

## example usage command ##
# snakemake --use-conda --conda-prefix ${CONDA_PREFIX}/envs -j 2 -p

# `--use-conda` – this specifies to use the conda environments included in the workflow
# `--conda-prefix` – this allows us to point to where the needed conda environments should be stored. Including this means if we use the workflow on a different dataset somewhere else in the future, it will re-use the same conda environments rather than make new ones. The value listed here, `${CONDA_PREFIX}/envs`, is the default location for conda environments (the variable `${CONDA_PREFIX}` will be expanded to the appropriate location on whichever system it is run on).
# `-j` – this lets us set how many jobs Snakemake should run concurrently (keep in mind that many of the thread and cpu parameters set in the config.yaml file will be multiplied by this)
# `-p` – specifies to print out each command being run to the screen

# See `snakemake -h` for more options and details.